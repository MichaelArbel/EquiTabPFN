seed: 0
system:
  device: 0 
  dtype: 32


n_samples: 1152
max_features: 100
max_num_classes: 10

data_path: 'data'

worker:
  rank: 0
  world_size: 1
  gpu: 0
  distributed: False


dataloader:
  batch_size: 24
  num_steps: 384
  min_eval_pos: 2
  max_eval_pos: 1000

training:
  aggregate_k_gradients: 3
  epochs: 1200
  train_mixed_precision: True
  eval_freq: 1
  ckpt_freq: 10
  compile: False
  distributed_mode: "DDP"

optimizer:
  name: 'torch.optim.AdamW'
  kwargs:
    lr: 0.0001
    weight_decay: 0.0

scheduler:
  warmup_epoch: 10
  first:
    name: 'torch.optim.lr_scheduler.LinearLR'
    kwargs: 
      start_factor: 0.0000000001
      end_factor: 1 
      total_iters: 10

  second:
    name: 'torch.optim.lr_scheduler.CosineAnnealingLR'
    kwargs:
      T_max: 1190
      eta_min: 0.00000001


load:
  model_state_path: ''
  load_model_strict: True
  load_existing_cktp: True

mode:
  eval_mode: True
  train_mode: True
